{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfvEzESm+u+GwpVaCojHC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thayane25/PLN/blob/main/RedesNeurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Redes Neurais em Processamento de Linguagem Natural"
      ],
      "metadata": {
        "id": "NX88llruahe_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch4m3JUYZ9E-",
        "outputId": "eefe4e90-30f1-4c9c-ca0c-8984e62190de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importação de bibliotecas bem sucedida!\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print(\"Importação de bibliotecas bem sucedida!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjunto de dados de treinamento (pequeno e simplificado)\n",
        "textos_treinamento = [\n",
        "    \"eu gosto de programar em python\",\n",
        "    \"python é uma linguagem poderosa\",\n",
        "    \"programar é divertido com python\",\n",
        "    \"aprenda python e seja feliz\",\n",
        "    \"gosto de aprender coisas novas\"\n",
        "]\n",
        "print(f\"Textos de treinamento: {textos_treinamento}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fPuFRkRaXDQ",
        "outputId": "d27fee7a-7690-4f46-e097-294ebeb5875d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Textos de treinamento: ['eu gosto de programar em python', 'python é uma linguagem poderosa', 'programar é divertido com python', 'aprenda python e seja feliz', 'gosto de aprender coisas novas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Construir o vocabulário a partir dos textos\n",
        "tokenizer.fit_on_texts(textos_treinamento)\n",
        "\n",
        "# Converter textos em sequência de números\n",
        "sequencias = tokenizer.texts_to_sequences(textos_treinamento)\n",
        "\n",
        "# Imprimir o vocabulário e as sequências geradas\n",
        "print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n",
        "print(f\"Sequência numéricas dos textos: {sequencias}\")\n",
        "\n",
        "# Calcular o tamanho do vocabulário (+1 para incluir o 0 de padding)\n",
        "total_palavras = len(tokenizer.word_index) + 1\n",
        "print (f\"Tamanho total do vocabulário: {total_palavras}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbYpBBXCavRk",
        "outputId": "8ea624ba-a434-4dbb-c569-e8dad0bf840f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulário (palavra: índice): {'python': 1, 'gosto': 2, 'de': 3, 'programar': 4, 'é': 5, 'eu': 6, 'em': 7, 'uma': 8, 'linguagem': 9, 'poderosa': 10, 'divertido': 11, 'com': 12, 'aprenda': 13, 'e': 14, 'seja': 15, 'feliz': 16, 'aprender': 17, 'coisas': 18, 'novas': 19}\n",
            "Sequência numéricas dos textos: [[6, 2, 3, 4, 7, 1], [1, 5, 8, 9, 10], [4, 5, 11, 12, 1], [13, 1, 14, 15, 16], [2, 3, 17, 18, 19]]\n",
            "Tamanho total do vocabulário: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar entradas (x) e saídas (y) para a previsão da próxima palavra\n",
        "# a entrada (x) será uma sequência de palavras, e a saída (y) será a palavra seguinte.\n",
        "# Determinar o comprimento máximo das sequências para padding\n",
        "max_comprimento = max(len(seq) for seq in sequencias)\n",
        "print(f\"\\nComprimento máximo das sequências antes do padding: {max_comprimento}\")\n",
        "\n",
        "# Criar pares de entrada (sequência parcial) e saída (próxima palavra)\n",
        "# Ex: \"Eu gosto de programar\" -> \"em\"\n",
        "#     \"gosto de programar em\" -> \"python\"\n",
        "entradas_X = []\n",
        "saidas_y = []\n",
        "\n",
        "for seq in sequencias:\n",
        "    for i in range(1,len(seq)):\n",
        "      entradas_X.append(seq[:i]) # A sequência até a palavra atual\n",
        "      saidas_y.append(seq[i]) # A próxima palavra\n",
        "\n",
        "print(f\"Exemplo de entradas_X (parcial): {entradas_X[0:5]}\")\n",
        "print(f\"Exemplo de saidas_y (parcial): {saidas_y[0:5]}\")\n",
        "\n",
        "# Padronizar o comprimento das sequências de entrada\n",
        "# Todas as sequências de entrada precisam ter o mesmo comprimento para a RNN\n",
        "entradas_X_padded = pad_sequences(entradas_X, maxlen=max_comprimento -1, padding='pre')\n",
        "# O maxlen é 'max_comprimento -1' porque a saída 'y' é a última palavra, então X sempre terá 1 palavra a menos.\n",
        "\n",
        "# Converter as saídas para o formato one-hot encoding\n",
        "# Isso é necessário para a ccamada de saída da RNN (softmax)\n",
        "saidas_y_one_hot = tf.keras.utils.to_categorical(saidas_y, num_classes=total_palavras)\n",
        "\n",
        "print(f\"\\nExemplo de entradas_X_padded (após padding e truncagem): \\n{entradas_X_padded[0:5]}\")\n",
        "print(f\"Exemplo de saidas_y_one_hot (após on)\")\n",
        "print(f\"Formato final das entradas (x): {entradas_X_padded.shape}\")\n",
        "print(f\"Formato final das saídas (y): {saidas_y_one_hot.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJVWzv05av8U",
        "outputId": "522f6bf3-22f2-4ea3-f8f6-da82d8363dc9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comprimento máximo das sequências antes do padding: 6\n",
            "Exemplo de entradas_X (parcial): [[6], [6, 2], [6, 2, 3], [6, 2, 3, 4], [6, 2, 3, 4, 7]]\n",
            "Exemplo de saidas_y (parcial): [2, 3, 4, 7, 1]\n",
            "\n",
            "Exemplo de entradas_X_padded (após padding e truncagem): \n",
            "[[0 0 0 0 6]\n",
            " [0 0 0 6 2]\n",
            " [0 0 6 2 3]\n",
            " [0 6 2 3 4]\n",
            " [6 2 3 4 7]]\n",
            "Exemplo de saidas_y_one_hot (após on)\n",
            "Formato final das entradas (x): (21, 5)\n",
            "Formato final das saídas (y): (21, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definindo o modelo\n",
        "# Definir a arquitetura do modelo RNN\n",
        "modelo_rnn = Sequential()\n",
        "\n",
        "# Camada de Embedding:\n",
        "# total_palavras: tamanho do vocabulário\n",
        "# 10: dimensão do vetor de embedding (quantas características queremos para cada palavra)\n",
        "# input_length: comprimento das sequências de entrada (maxlen - 1)\n",
        "modelo_rnn.add(Embedding(total_palavras, 10, input_length=entradas_X_padded.shape[1]))\n",
        "\n",
        "# Camada SimpleRNN:\n",
        "# 32: número de unidades (neurônios) na camada recorrente. Este é o tamanho do estado oculto.\n",
        "modelo_rnn.add(SimpleRNN(32))\n",
        "\n",
        "# Camada Densa de Saída:\n",
        "# total_palavras: número de neurônios de saída (um para cada palavra no vocabulário)\n",
        "# activation='softmax': função de ativação para probabilidade (soma 1 para todas as palavras)\n",
        "modelo_rnn.add(Dense(total_palavras, activation='softmax'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Exibir um resumo da arquitetura do modelo\n",
        "modelo_rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "n43GNqqGaz4t",
        "outputId": "c741cd13-5a1b-4412-a31e-08f5aa72ec38"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando o modelo\n",
        "print(\"\\nIniciando o treinamento do modelo RNN...\")\n",
        "modelo_rnn.fit(entradas_X_padded, saidas_y_one_hot, epochs=100, verbose=1)\n",
        "    # epochs: quantas vezes o modelo verá todo o conjunto de dados\n",
        "    # verbose: 1 para mostrar o progresso do treinamento\n",
        "print(\"Treinamento concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjIg2A9ja4Op",
        "outputId": "26904580-9a29-44ff-9187-a3a0c5eed1fb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo RNN...\n",
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 2.9947\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0476 - loss: 2.9873\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0952 - loss: 2.9800\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0952 - loss: 2.9728\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1429 - loss: 2.9655\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.1905 - loss: 2.9582\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2381 - loss: 2.9509\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2381 - loss: 2.9434\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2381 - loss: 2.9357\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2857 - loss: 2.9279\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2857 - loss: 2.9198\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3333 - loss: 2.9116\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3333 - loss: 2.9030\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3333 - loss: 2.8942\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3333 - loss: 2.8850\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3333 - loss: 2.8755\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3333 - loss: 2.8656\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3333 - loss: 2.8553\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3333 - loss: 2.8446\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3333 - loss: 2.8335\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3333 - loss: 2.8220\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3333 - loss: 2.8100\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3333 - loss: 2.7976\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3333 - loss: 2.7847\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3333 - loss: 2.7713\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2857 - loss: 2.7575\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2857 - loss: 2.7432\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2857 - loss: 2.7285\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2857 - loss: 2.7134\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2857 - loss: 2.6978\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2857 - loss: 2.6818\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2857 - loss: 2.6654\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2857 - loss: 2.6485\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2857 - loss: 2.6312\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2857 - loss: 2.6134\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2857 - loss: 2.5952\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2857 - loss: 2.5764\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2857 - loss: 2.5570\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2857 - loss: 2.5371\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3333 - loss: 2.5166\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3333 - loss: 2.4956\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3333 - loss: 2.4739\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3333 - loss: 2.4518\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3333 - loss: 2.4291\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 2.4060\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.3333 - loss: 2.3824\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3333 - loss: 2.3585\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3333 - loss: 2.3342\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3810 - loss: 2.3096\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3810 - loss: 2.2848\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.3810 - loss: 2.2597\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3810 - loss: 2.2345\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3810 - loss: 2.2091\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3810 - loss: 2.1835\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4286 - loss: 2.1578\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4286 - loss: 2.1319\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5238 - loss: 2.1059\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5238 - loss: 2.0798\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5714 - loss: 2.0535\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5714 - loss: 2.0271\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5714 - loss: 2.0006\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5238 - loss: 1.9741\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5238 - loss: 1.9474\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5238 - loss: 1.9207\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5714 - loss: 1.8939\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5714 - loss: 1.8672\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5714 - loss: 1.8404\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5714 - loss: 1.8136\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5714 - loss: 1.7868\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6190 - loss: 1.7600\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7143 - loss: 1.7333\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8095 - loss: 1.7066\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8095 - loss: 1.6800\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8095 - loss: 1.6534\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8095 - loss: 1.6269\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8095 - loss: 1.6006\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8095 - loss: 1.5743\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8095 - loss: 1.5482\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8095 - loss: 1.5222\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8095 - loss: 1.4964\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8571 - loss: 1.4708\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8571 - loss: 1.4454\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8571 - loss: 1.4202\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8571 - loss: 1.3952\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8571 - loss: 1.3704\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8571 - loss: 1.3458\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8571 - loss: 1.3215\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8571 - loss: 1.2974\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8571 - loss: 1.2736\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8571 - loss: 1.2501\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8571 - loss: 1.2268\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8571 - loss: 1.2038\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8571 - loss: 1.1811\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8571 - loss: 1.1587\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8571 - loss: 1.1366\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8571 - loss: 1.1148\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8571 - loss: 1.0933\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8571 - loss: 1.0722\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8571 - loss: 1.0514\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8571 - loss: 1.0310\n",
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Função de Previsão:\n",
        "def prever_proxima_palavra(modelo, tokenizer, max_seq_len, texto_base):\n",
        "    \"\"\"\n",
        "    Prevê a próxima palavra dado um texto base.\n",
        "    \"\"\"\n",
        "    # Converter o texto base para sequência numérica\n",
        "    sequencia_numerica = tokenizer.texts_to_sequences([texto_base])[0]\n",
        "\n",
        "    # Padronizar o comprimento da sequência de entrada (precisa ter o mesmo formato que o treinamento)\n",
        "    # Atenção: max_seq_len deve ser o comprimento que as *entradas* foram pad_sequenciadas\n",
        "    sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='pre')\n",
        "\n",
        "    # Fazer a previsão\n",
        "    previsao_probabilidades = modelo.predict(sequencia_padded, verbose=0)[0]\n",
        "\n",
        "    # Obter o índice da palavra com a maior probabilidade\n",
        "    indice_palavra_prevista = np.argmax(previsao_probabilidades)\n",
        "\n",
        "    # Converter o índice de volta para a palavra\n",
        "    for palavra, indice in tokenizer.word_index.items():\n",
        "        if indice == indice_palavra_prevista:\n",
        "            return palavra\n",
        "    return None  # Caso a palavra não seja encontrada (improvável com o vocabulário ajustado)\n",
        "\n",
        "# Comprimento de entrada esperado pelo modelo\n",
        "# entradas_X_padded.shape[1] é o maxlen que usamos no pad_sequences para X\n",
        "comprimento_entrada_modelo = entradas_X_padded.shape[1]\n",
        "\n",
        "# Testar o modelo com novas frases\n",
        "print(\"\\n-- Testando o Modelo RNN --\\n\")\n",
        "\n",
        "texto_teste_1 = \"eu gosto de\"\n",
        "proxima_1 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_1)\n",
        "print(f\"Texto: '{texto_teste_1}' -> Próxima palavra prevista: '{proxima_1}'\")\n",
        "\n",
        "texto_teste_2 = \"python é uma\"\n",
        "proxima_2 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_2)\n",
        "print(f\"Texto: '{texto_teste_2}' -> Próxima palavra prevista: '{proxima_2}'\")\n",
        "\n",
        "texto_teste_3 = \"programar é divertido\"\n",
        "proxima_3 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_3)\n",
        "print(f\"Texto: '{texto_teste_3}' -> Próxima palavra prevista: '{proxima_3}'\")\n",
        "\n",
        "texto_teste_4 = \"aprenda python e\"\n",
        "proxima_4 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_4)\n",
        "print(f\"Texto: '{texto_teste_4}' -> Próxima palavra prevista: '{proxima_4}'\")\n",
        "\n",
        "# Exemplo com palavra fora do vocabulário (ou sequência que o modelo nunca viu antes)\n",
        "texto_teste_5 = \"o sol brilha no\"\n",
        "# \"sol\" e \"brilha\" não estão no vocabulário\n",
        "proxima_5 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_5)\n",
        "print(f\"Texto: '{texto_teste_5}' -> Próxima palavra prevista: '{proxima_5}' (Pode ser inesperada devido a palavras desconhecidas)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJE_vE5Ha7bL",
        "outputId": "6d5a6968-ffff-4208-f41b-45177fa5c082"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Testando o Modelo RNN --\n",
            "\n",
            "Texto: 'eu gosto de' -> Próxima palavra prevista: 'programar'\n",
            "Texto: 'python é uma' -> Próxima palavra prevista: 'linguagem'\n",
            "Texto: 'programar é divertido' -> Próxima palavra prevista: 'com'\n",
            "Texto: 'aprenda python e' -> Próxima palavra prevista: 'seja'\n",
            "Texto: 'o sol brilha no' -> Próxima palavra prevista: 'é' (Pode ser inesperada devido a palavras desconhecidas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ2ltbeybBZ0",
        "outputId": "5cfb0e23-e3d5-4d2c-af69-287330f049f2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definir o Conjunto de Dados (Frases e Rótulos) para análise de sentimentos\n",
        "dados_sentimento = [\n",
        "    (\"este filme é ótimo e divertido\", \"positivo\"),\n",
        "    (\"adorei muito, muito bom\", \"positivo\"),\n",
        "    (\"foi uma ótima atuação dos atores\", \"positivo\"),\n",
        "    (\"o roteiro é fraco e chato\", \"negativo\"),\n",
        "    (\"não gostei do produto\", \"negativo\"),\n",
        "    (\"uma perda de tempo\", \"negativo\"),\n",
        "    (\"filme terrível, inacabável\", \"negativo\"),\n",
        "    (\"atuação muito ruim\", \"negativo\"),\n",
        "    (\"excelente serviço, muito eficiente\", \"positivo\"),\n",
        "    (\"decepcionante\", \"negativo\"),\n",
        "    (\"experiência mágica e fascinante\", \"positivo\"),\n",
        "    (\"plano de viagem interessante\", \"positivo\"),\n",
        "    (\"comprei várias vezes\", \"negativo\"),\n",
        "    (\"interface é confusa e difícil\", \"negativo\"),\n",
        "    (\"ótimo suporte, útil e rápido\", \"positivo\"),\n",
        "]\n",
        "\n",
        "textos = [dado[0] for dado in dados_sentimento]\n",
        "sentimentos = [dado[1] for dado in dados_sentimento]\n",
        "\n",
        "print(f\"Total de frases: {len(textos)}\")\n",
        "print(f\"Exemplo de textos: {textos[:3]}\")\n",
        "print(f\"Exemplo de sentimentos: {sentimentos[:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhnyLmsPbDjD",
        "outputId": "7de5080c-50b7-4327-cf04-02357448a133"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de frases: 15\n",
            "Exemplo de textos: ['este filme é ótimo e divertido', 'adorei muito, muito bom', 'foi uma ótima atuação dos atores']\n",
            "Exemplo de sentimentos: ['positivo', 'positivo', 'positivo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Mapear Sentimentos para Números: converter \"positivo\" e \"negativo\" para 0 e 1.\n",
        "mapeamento_sentimento = {'negativo': 0, 'positivo': 1}\n",
        "rotulos_numericos = np.array([mapeamento_sentimento[s] for s in sentimentos])\n",
        "print(f\"\\nSentimentos mapeados para números: {rotulos_numericos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MMuind4bFcw",
        "outputId": "968020b5-fbd4-4548-f6fc-43ff05f76aa4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentimentos mapeados para números: [1 1 1 0 0 0 0 0 1 0 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Tokenização do Texto\n",
        "tokenizer = Tokenizer(num_words=None, oov_token=\"unk\")\n",
        "# num_words=None para pegar todo o vocabulário\n",
        "# oov_token para palavras desconhecidas\n",
        "tokenizer.fit_on_texts(textos)\n",
        "sequences_numericas = tokenizer.texts_to_sequences(textos)\n",
        "\n",
        "total_palavras_vocab = len(tokenizer.word_index) + 1  # +1 para o 0 de padding/OOV\n",
        "\n",
        "print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n",
        "print(f\"Sequências numéricas das frases: {sequences_numericas}\")\n",
        "print(f\"Tamanho total do vocabulário: {total_palavras_vocab}\")\n",
        "\n",
        "# 4. Padronizar o comprimento das sequências\n",
        "# Encontrar o comprimento da frase mais longa para padronizar\n",
        "max_len = max(len(s) for s in sequences_numericas)\n",
        "print(f\"\\nComprimento máximo das sequências: {max_len}\")\n",
        "\n",
        "entradas_padded = pad_sequences(sequences_numericas, maxlen=max_len, padding='post')  # 'post' para adicionar zeros no final\n",
        "print(f\"Sequências após padding: \\n{entradas_padded}\")\n",
        "\n",
        "# 5. Dividir os dados em conjuntos de treinamento e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    entradas_padded, rotulos_numericos, test_size=0.2, random_state=42, stratify=rotulos_numericos\n",
        ")\n",
        "\n",
        "print(f\"\\nShape de X_treino: {X_treino.shape}\")\n",
        "print(f\"Shape de X_teste: {X_teste.shape}\")\n",
        "print(f\"Shape de y_treino: {y_treino.shape}\")\n",
        "print(f\"Shape de y_teste: {y_teste.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc9DiaEubHGh",
        "outputId": "b6e4717a-80aa-43b2-9c0b-1bbac6add807"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulário (palavra: índice): {'unk': 1, 'e': 2, 'muito': 3, 'é': 4, 'filme': 5, 'ótimo': 6, 'uma': 7, 'atuação': 8, 'de': 9, 'este': 10, 'divertido': 11, 'adorei': 12, 'bom': 13, 'foi': 14, 'ótima': 15, 'dos': 16, 'atores': 17, 'o': 18, 'roteiro': 19, 'fraco': 20, 'chato': 21, 'não': 22, 'gostei': 23, 'do': 24, 'produto': 25, 'perda': 26, 'tempo': 27, 'terrível': 28, 'inacabável': 29, 'ruim': 30, 'excelente': 31, 'serviço': 32, 'eficiente': 33, 'decepcionante': 34, 'experiência': 35, 'mágica': 36, 'fascinante': 37, 'plano': 38, 'viagem': 39, 'interessante': 40, 'comprei': 41, 'várias': 42, 'vezes': 43, 'interface': 44, 'confusa': 45, 'difícil': 46, 'suporte': 47, 'útil': 48, 'rápido': 49}\n",
            "Sequências numéricas das frases: [[10, 5, 4, 6, 2, 11], [12, 3, 3, 13], [14, 7, 15, 8, 16, 17], [18, 19, 4, 20, 2, 21], [22, 23, 24, 25], [7, 26, 9, 27], [5, 28, 29], [8, 3, 30], [31, 32, 3, 33], [34], [35, 36, 2, 37], [38, 9, 39, 40], [41, 42, 43], [44, 4, 45, 2, 46], [6, 47, 48, 2, 49]]\n",
            "Tamanho total do vocabulário: 50\n",
            "\n",
            "Comprimento máximo das sequências: 6\n",
            "Sequências após padding: \n",
            "[[10  5  4  6  2 11]\n",
            " [12  3  3 13  0  0]\n",
            " [14  7 15  8 16 17]\n",
            " [18 19  4 20  2 21]\n",
            " [22 23 24 25  0  0]\n",
            " [ 7 26  9 27  0  0]\n",
            " [ 5 28 29  0  0  0]\n",
            " [ 8  3 30  0  0  0]\n",
            " [31 32  3 33  0  0]\n",
            " [34  0  0  0  0  0]\n",
            " [35 36  2 37  0  0]\n",
            " [38  9 39 40  0  0]\n",
            " [41 42 43  0  0  0]\n",
            " [44  4 45  2 46  0]\n",
            " [ 6 47 48  2 49  0]]\n",
            "\n",
            "Shape de X_treino: (12, 6)\n",
            "Shape de X_teste: (3, 6)\n",
            "Shape de y_treino: (12,)\n",
            "Shape de y_teste: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura do modelo LSTM\n",
        "modelo_lstm = Sequential()\n",
        "\n",
        "# Camada de Embedding: Converte os índices numéricos das palavras em vetores densos.\n",
        "# total_palavras_vocab: tamanho do vocabulário\n",
        "# 50: dimensão do vetor de embedding (pode ser ajustado)\n",
        "# input_length: comprimento padronizado das sequências (max_len)\n",
        "modelo_lstm.add(Embedding(total_palavras_vocab, 50, input_length=max_len))\n",
        "\n",
        "# Camada LSTM:\n",
        "# 64: número de unidades (neurônios) na camada LSTM. Define o tamanho do estado oculto e da célula de memória.\n",
        "# dropout: Um tipo de regularização para evitar overfitting (descarta aleatoriamente neurônios durante o treinamento).\n",
        "# recurrent_dropout: Dropout aplicado nas conexões recorrentes da LSTM.\n",
        "modelo_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "# Camada Densa de Saída:\n",
        "# 1: Um único neurônio de saída, pois é um problema de classificação binária (positivo/negativo).\n",
        "# activation='sigmoid': Função de ativação para classificação binária (produz um valor entre 0 e 1).\n",
        "modelo_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Exibir um resumo da arquitetura do modelo\n",
        "modelo_lstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "9FPcKUjhbI_j",
        "outputId": "6851733e-f379-42a1-e42f-59deaeecadea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "print(\"\\nIniciando o treinamento do modelo LSTM...\")\n",
        "historico = modelo_lstm.fit(\n",
        "    X_treino, y_treino,\n",
        "    epochs=50,  # Reduzi para 50 epochs para um treinamento mais rápido no exemplo. Pode ser aumentado.\n",
        "    batch_size=2,  # Pequeno batch_size para dataset pequeno.\n",
        "    validation_split=0.1,  # Usar 10% do treino para validação\n",
        "    verbose=1\n",
        ")\n",
        "# epochs: número de vezes que o modelo verá todo o conjunto de dados de treinamento.\n",
        "# batch_size: número de amostras por atualização de gradiente.\n",
        "# validation_split: % dos dados de treino usados para validação durante o treinamento (opcional, mas bom para monitorar overfitting).\n",
        "print(\"Treinamento concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN1VIxTgbK0L",
        "outputId": "db8b5b2b-972e-4eb3-db37-8bf4ad95762f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo LSTM...\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - accuracy: 0.3847 - loss: 0.6944 - val_accuracy: 0.5000 - val_loss: 0.6916\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7403 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6911\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7194 - loss: 0.6894 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7111 - loss: 0.6874 - val_accuracy: 0.0000e+00 - val_loss: 0.6966\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8639 - loss: 0.6769 - val_accuracy: 0.0000e+00 - val_loss: 0.7010\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8847 - loss: 0.6742 - val_accuracy: 0.0000e+00 - val_loss: 0.7059\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9458 - loss: 0.6575 - val_accuracy: 0.0000e+00 - val_loss: 0.7158\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.6401 - val_accuracy: 0.0000e+00 - val_loss: 0.7330\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.6124 - val_accuracy: 0.0000e+00 - val_loss: 0.7606\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.5703 - val_accuracy: 0.0000e+00 - val_loss: 0.8150\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.4644 - val_accuracy: 0.0000e+00 - val_loss: 0.9245\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.3833 - val_accuracy: 0.0000e+00 - val_loss: 1.1450\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.2534 - val_accuracy: 0.0000e+00 - val_loss: 1.5299\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0924 - val_accuracy: 0.0000e+00 - val_loss: 2.0883\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0508 - val_accuracy: 0.0000e+00 - val_loss: 2.7047\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.0000e+00 - val_loss: 3.3032\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.0000e+00 - val_loss: 3.7740\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.0000e+00 - val_loss: 4.1173\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 4.3609\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 4.5312\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.0000e+00 - val_loss: 4.6638\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.0000e+00 - val_loss: 4.7613\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.0000e+00 - val_loss: 4.8408\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.0000e+00 - val_loss: 4.9048\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.0000e+00 - val_loss: 4.9586\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.0000e+00 - val_loss: 5.0098\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0000e+00 - val_loss: 5.0532\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.0000e+00 - val_loss: 5.0964\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.0000e+00 - val_loss: 5.1445\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0000e+00 - val_loss: 5.1904\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0000e+00 - val_loss: 5.2292\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 5.2623\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 5.3016\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 5.3349\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0000e+00 - val_loss: 5.3660\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.2920e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.4012\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0000e+00 - val_loss: 5.4335\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.0000e+00 - val_loss: 5.4692\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 5.5125\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.0228e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.5527\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0000e+00 - val_loss: 5.5868\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.9144e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6178\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.4584e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6453\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.9091e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6725\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.8395e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7009\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.4642e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7302\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.7977e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7584\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.7875e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7821\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.8220e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8077\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.1098e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8300\n",
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avalia o modelo no conjunto de teste\n",
        "perda, acuracia = modelo_lstm.evaluate(X_teste, y_teste, verbose=0)\n",
        "print(f\"\\nAcurácia do modelo no conjunto de teste: {acuracia*100:.2f}%\")\n",
        "print(f\"Perda do modelo no conjunto de teste: {perda:.4f}\")\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred_prob = modelo_lstm.predict(X_teste)\n",
        "y_pred_classes = (y_pred_prob > 0.5).astype(int)  # Converter probabilidades para 0 ou 1\n",
        "\n",
        "print(\"\\n-- Relatório de Classificação --\")\n",
        "print(classification_report(y_teste, y_pred_classes, target_names=['negativo', 'positivo']))\n",
        "\n",
        "print(\"\\n-- Matriz de Confusão --\")\n",
        "cm = confusion_matrix(y_teste, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=['negativo', 'positivo'], yticklabels=['negativo', 'positivo'])\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "Vx6GXc08bNVo",
        "outputId": "9a7e45ad-3893-4961-b2ae-657f678a8aa0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Acurácia do modelo no conjunto de teste: 66.67%\n",
            "Perda do modelo no conjunto de teste: 0.4038\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
            "\n",
            "-- Relatório de Classificação --\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.67      1.00      0.80         2\n",
            "    positivo       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.33      0.50      0.40         3\n",
            "weighted avg       0.44      0.67      0.53         3\n",
            "\n",
            "\n",
            "-- Matriz de Confusão --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando o modelo treinado\n",
        "def prever_sentimento(modelo, tokenizer, max_seq_len, frase_nova, mapeamento_sentimento):\n",
        "    \"\"\"\n",
        "    Prevê o sentimento de uma nova frase.\n",
        "    \"\"\"\n",
        "    # Converter a frase para sequência numérica\n",
        "    sequencia_numerica = tokenizer.texts_to_sequences([frase_nova])\n",
        "\n",
        "    # Se a frase tem palavras desconhecidas, o tokenizer pode retornar uma lista vazia ou valores 0\n",
        "    if not sequencia_numerica:\n",
        "        print(f\"Aviso: a frase '{frase_nova}' contém apenas palavras desconhecidas.\")\n",
        "        return \"Desconhecido\"  # Ou outra indicação\n",
        "\n",
        "    sequencia_numerica = sequencia_numerica[0]  # Pega a primeira (e única) sequência\n",
        "\n",
        "    # Padronizar o comprimento da sequência de entrada\n",
        "    sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='post')\n",
        "\n",
        "    # Fazer a previsão (probabilidade)\n",
        "    probabilidade_positiva = modelo.predict(sequencia_padded, verbose=0)[0][0]\n",
        "\n",
        "    # Inverter o mapeamento para obter o nome do sentimento\n",
        "    mapeamento_inverso = {v: k for k, v in mapeamento_sentimento.items()}\n",
        "\n",
        "    # Classificar com base no limiar de 0.5\n",
        "    if probabilidade_positiva >= 0.5:\n",
        "        return mapeamento_inverso[1]  # 'positivo'\n",
        "    else:\n",
        "        return mapeamento_inverso[0]  # 'negativo'\n",
        "\n",
        "# Testar o modelo com novas frases\n",
        "print(\"\\n-- Testando Modelo LSTM com Novas Frases ---\")\n",
        "\n",
        "frase_nova_1 = \"gostei muito do filme, excelente!\"\n",
        "sentimento_1 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_1, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_1}' -> Sentimento previsto: '{sentimento_1}'\")\n",
        "\n",
        "frase_nova_2 = \"odiei o livro, muito entediante\"\n",
        "sentimento_2 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_2, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_2}' -> Sentimento previsto: '{sentimento_2}'\")\n",
        "\n",
        "frase_nova_3 = \"a aula de pln é ótima\"\n",
        "sentimento_3 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_3, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_3}' -> Sentimento previsto: '{sentimento_3}'\")\n",
        "\n",
        "frase_nova_4 = \"o atendimento foi péssimo\"\n",
        "sentimento_4 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_4, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_4}' -> Sentimento previsto: '{sentimento_4}'\")\n",
        "\n",
        "frase_nova_5 = \"esse produto não vale a pena, é caro\"\n",
        "sentimento_5 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_5, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_5}' -> Sentimento previsto: '{sentimento_5}'\")\n",
        "\n",
        "frase_nova_6 = \"o filme é legal\"  # Frase curta e ambígua para um modelo pequeno\n",
        "sentimento_6 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_6, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_6}' -> Sentimento previsto: '{sentimento_6}'\")\n",
        "\n",
        "frase_nova_7 = \"isso é horrível, que tristeza\"\n",
        "sentimento_7 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_7, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_7}' -> Sentimento previsto: '{sentimento_7}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuZcQF6MbP0z",
        "outputId": "4814fdc0-410f-4945-906c-95566961bc19"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Testando Modelo LSTM com Novas Frases ---\n",
            "Frase: 'gostei muito do filme, excelente!' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'odiei o livro, muito entediante' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'a aula de pln é ótima' -> Sentimento previsto: 'positivo'\n",
            "Frase: 'o atendimento foi péssimo' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'esse produto não vale a pena, é caro' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'o filme é legal' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'isso é horrível, que tristeza' -> Sentimento previsto: 'negativo'\n"
          ]
        }
      ]
    }
  ]
}